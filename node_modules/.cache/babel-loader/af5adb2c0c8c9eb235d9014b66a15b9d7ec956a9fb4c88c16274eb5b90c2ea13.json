{"ast":null,"code":"/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { runWhenIdle } from '../../../base/common/async.js';\nimport { BugIndicatingError, onUnexpectedError } from '../../../base/common/errors.js';\nimport { Disposable, MutableDisposable } from '../../../base/common/lifecycle.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { TokenizationRegistry } from '../languages.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\n/**\n * An array that avoids being sparse by always\n * filling up unused indices with a default value.\n */\nexport class ContiguousGrowingArray {\n  constructor(_default) {\n    this._default = _default;\n    this._store = [];\n  }\n  get(index) {\n    if (index < this._store.length) {\n      return this._store[index];\n    }\n    return this._default;\n  }\n  set(index, value) {\n    while (index >= this._store.length) {\n      this._store[this._store.length] = this._default;\n    }\n    this._store[index] = value;\n  }\n  // TODO have `replace` instead of `delete` and `insert`\n  delete(deleteIndex, deleteCount) {\n    if (deleteCount === 0 || deleteIndex >= this._store.length) {\n      return;\n    }\n    this._store.splice(deleteIndex, deleteCount);\n  }\n  insert(insertIndex, insertCount) {\n    if (insertCount === 0 || insertIndex >= this._store.length) {\n      return;\n    }\n    const arr = [];\n    for (let i = 0; i < insertCount; i++) {\n      arr[i] = this._default;\n    }\n    this._store = arrays.arrayInsert(this._store, insertIndex, arr);\n  }\n}\n/**\n * Stores the states at the start of each line and keeps track of which lines\n * must be re-tokenized. Also uses state equality to quickly validate lines\n * that don't need to be re-tokenized.\n *\n * For example, when typing on a line, the line gets marked as needing to be tokenized.\n * Once the line is tokenized, the end state is checked for equality against the begin\n * state of the next line. If the states are equal, tokenization doesn't need to run\n * again over the rest of the file. If the states are not equal, the next line gets marked\n * as needing to be tokenized.\n */\nexport class TokenizationStateStore {\n  get invalidLineStartIndex() {\n    return this._firstLineNeedsTokenization;\n  }\n  constructor(tokenizationSupport, initialState) {\n    this.tokenizationSupport = tokenizationSupport;\n    this.initialState = initialState;\n    /**\n     * `lineBeginState[i]` contains the begin state used to tokenize line number `i + 1`.\n     */\n    this._lineBeginState = new ContiguousGrowingArray(null);\n    /**\n     * `lineNeedsTokenization[i]` describes if line number `i + 1` needs to be tokenized.\n     */\n    this._lineNeedsTokenization = new ContiguousGrowingArray(true);\n    this._firstLineNeedsTokenization = 0;\n    this._lineBeginState.set(0, this.initialState);\n  }\n  markMustBeTokenized(lineIndex) {\n    this._lineNeedsTokenization.set(lineIndex, true);\n    this._firstLineNeedsTokenization = Math.min(this._firstLineNeedsTokenization, lineIndex);\n  }\n  getBeginState(lineIndex) {\n    return this._lineBeginState.get(lineIndex);\n  }\n  setEndState(linesLength, lineIndex, endState) {\n    this._lineNeedsTokenization.set(lineIndex, false);\n    this._firstLineNeedsTokenization = lineIndex + 1;\n    // Check if this was the last line\n    if (lineIndex === linesLength - 1) {\n      return false;\n    }\n    // Check if the end state has changed\n    const previousEndState = this._lineBeginState.get(lineIndex + 1);\n    if (previousEndState === null || !endState.equals(previousEndState)) {\n      this._lineBeginState.set(lineIndex + 1, endState);\n      this.markMustBeTokenized(lineIndex + 1);\n      return true;\n    }\n    // Perhaps we can skip tokenizing some lines...\n    let i = lineIndex + 1;\n    while (i < linesLength) {\n      if (this._lineNeedsTokenization.get(i)) {\n        break;\n      }\n      i++;\n    }\n    this._firstLineNeedsTokenization = i;\n    return false;\n  }\n  applyEdits(range, eolCount) {\n    this.markMustBeTokenized(range.startLineNumber - 1);\n    this._lineBeginState.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n    this._lineNeedsTokenization.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n    this._lineBeginState.insert(range.startLineNumber, eolCount);\n    this._lineNeedsTokenization.insert(range.startLineNumber, eolCount);\n  }\n  updateTokensUntilLine(textModel, languageIdCodec, builder, lineNumber) {\n    const languageId = textModel.getLanguageId();\n    const linesLength = textModel.getLineCount();\n    const endLineIndex = lineNumber - 1;\n    // Validate all states up to and including endLineIndex\n    for (let lineIndex = this.invalidLineStartIndex; lineIndex <= endLineIndex; lineIndex++) {\n      const text = textModel.getLineContent(lineIndex + 1);\n      const lineStartState = this.getBeginState(lineIndex);\n      const r = safeTokenize(languageIdCodec, languageId, this.tokenizationSupport, text, true, lineStartState);\n      builder.add(lineIndex + 1, r.tokens);\n      this.setEndState(linesLength, lineIndex, r.endState);\n      lineIndex = this.invalidLineStartIndex - 1; // -1 because the outer loop increments it\n    }\n  }\n\n  isTokenizationComplete(textModel) {\n    return this.invalidLineStartIndex >= textModel.getLineCount();\n  }\n}\nexport class TextModelTokenization extends Disposable {\n  constructor(_textModel, _tokenizationPart, _languageIdCodec) {\n    super();\n    this._textModel = _textModel;\n    this._tokenizationPart = _tokenizationPart;\n    this._languageIdCodec = _languageIdCodec;\n    this._tokenizationStateStore = null;\n    this._defaultBackgroundTokenizer = null;\n    this.backgroundTokenizer = this._register(new MutableDisposable());\n    this._register(TokenizationRegistry.onDidChange(e => {\n      const languageId = this._textModel.getLanguageId();\n      if (e.changedLanguages.indexOf(languageId) === -1) {\n        return;\n      }\n      this._resetTokenizationState();\n      this._tokenizationPart.clearTokens();\n    }));\n    this._resetTokenizationState();\n  }\n  handleDidChangeContent(e) {\n    var _a;\n    if (e.isFlush) {\n      this._resetTokenizationState();\n      return;\n    }\n    if (this._tokenizationStateStore) {\n      for (let i = 0, len = e.changes.length; i < len; i++) {\n        const change = e.changes[i];\n        const [eolCount] = countEOL(change.text);\n        this._tokenizationStateStore.applyEdits(change.range, eolCount);\n      }\n    }\n    (_a = this._defaultBackgroundTokenizer) === null || _a === void 0 ? void 0 : _a.handleChanges();\n  }\n  handleDidChangeAttached() {\n    var _a;\n    (_a = this._defaultBackgroundTokenizer) === null || _a === void 0 ? void 0 : _a.handleChanges();\n  }\n  handleDidChangeLanguage(e) {\n    this._resetTokenizationState();\n    this._tokenizationPart.clearTokens();\n  }\n  _resetTokenizationState() {\n    const [tokenizationSupport, initialState] = initializeTokenization(this._textModel, this._tokenizationPart);\n    if (tokenizationSupport && initialState) {\n      this._tokenizationStateStore = new TokenizationStateStore(tokenizationSupport, initialState);\n    } else {\n      this._tokenizationStateStore = null;\n    }\n    this.backgroundTokenizer.clear();\n    this._defaultBackgroundTokenizer = null;\n    if (this._tokenizationStateStore) {\n      const b = {\n        setTokens: tokens => {\n          this._tokenizationPart.setTokens(tokens);\n        },\n        backgroundTokenizationFinished: () => {\n          this._tokenizationPart.handleBackgroundTokenizationFinished();\n        },\n        setEndState: (lineNumber, state) => {\n          var _a, _b;\n          if (!state) {\n            throw new BugIndicatingError();\n          }\n          const invalidLineStartIndex = (_a = this._tokenizationStateStore) === null || _a === void 0 ? void 0 : _a.invalidLineStartIndex;\n          if (invalidLineStartIndex !== undefined && lineNumber - 1 >= invalidLineStartIndex) {\n            // Don't accept states for definitely valid states\n            (_b = this._tokenizationStateStore) === null || _b === void 0 ? void 0 : _b.setEndState(this._textModel.getLineCount(), lineNumber - 1, state);\n          }\n        }\n      };\n      if (tokenizationSupport && tokenizationSupport.createBackgroundTokenizer) {\n        this.backgroundTokenizer.value = tokenizationSupport.createBackgroundTokenizer(this._textModel, b);\n      }\n      if (!this.backgroundTokenizer.value) {\n        this.backgroundTokenizer.value = this._defaultBackgroundTokenizer = new DefaultBackgroundTokenizer(this._textModel, this._tokenizationStateStore, b, this._languageIdCodec);\n        this._defaultBackgroundTokenizer.handleChanges();\n      }\n    }\n  }\n  tokenizeViewport(startLineNumber, endLineNumber) {\n    var _a;\n    const builder = new ContiguousMultilineTokensBuilder();\n    this._heuristicallyTokenizeViewport(builder, startLineNumber, endLineNumber);\n    this._tokenizationPart.setTokens(builder.finalize());\n    (_a = this._defaultBackgroundTokenizer) === null || _a === void 0 ? void 0 : _a.checkFinished();\n  }\n  reset() {\n    this._resetTokenizationState();\n    this._tokenizationPart.clearTokens();\n  }\n  forceTokenization(lineNumber) {\n    var _a, _b;\n    const builder = new ContiguousMultilineTokensBuilder();\n    (_a = this._tokenizationStateStore) === null || _a === void 0 ? void 0 : _a.updateTokensUntilLine(this._textModel, this._languageIdCodec, builder, lineNumber);\n    this._tokenizationPart.setTokens(builder.finalize());\n    (_b = this._defaultBackgroundTokenizer) === null || _b === void 0 ? void 0 : _b.checkFinished();\n  }\n  getTokenTypeIfInsertingCharacter(position, character) {\n    if (!this._tokenizationStateStore) {\n      return 0 /* StandardTokenType.Other */;\n    }\n\n    this.forceTokenization(position.lineNumber);\n    const lineStartState = this._tokenizationStateStore.getBeginState(position.lineNumber - 1);\n    if (!lineStartState) {\n      return 0 /* StandardTokenType.Other */;\n    }\n\n    const languageId = this._textModel.getLanguageId();\n    const lineContent = this._textModel.getLineContent(position.lineNumber);\n    // Create the text as if `character` was inserted\n    const text = lineContent.substring(0, position.column - 1) + character + lineContent.substring(position.column - 1);\n    const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n    const lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n    if (lineTokens.getCount() === 0) {\n      return 0 /* StandardTokenType.Other */;\n    }\n\n    const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n    return lineTokens.getStandardTokenType(tokenIndex);\n  }\n  tokenizeLineWithEdit(position, length, newText) {\n    const lineNumber = position.lineNumber;\n    const column = position.column;\n    if (!this._tokenizationStateStore) {\n      return null;\n    }\n    this.forceTokenization(lineNumber);\n    const lineStartState = this._tokenizationStateStore.getBeginState(lineNumber - 1);\n    if (!lineStartState) {\n      return null;\n    }\n    const curLineContent = this._textModel.getLineContent(lineNumber);\n    const newLineContent = curLineContent.substring(0, column - 1) + newText + curLineContent.substring(column - 1 + length);\n    const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n    const result = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, newLineContent, true, lineStartState);\n    const lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n    return lineTokens;\n  }\n  isCheapToTokenize(lineNumber) {\n    if (!this._tokenizationStateStore) {\n      return true;\n    }\n    const firstInvalidLineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n    if (lineNumber > firstInvalidLineNumber) {\n      return false;\n    }\n    if (lineNumber < firstInvalidLineNumber) {\n      return true;\n    }\n    if (this._textModel.getLineLength(lineNumber) < 2048 /* Constants.CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n      return true;\n    }\n    return false;\n  }\n  /**\n   * The result is not cached.\n   */\n  _heuristicallyTokenizeViewport(builder, startLineNumber, endLineNumber) {\n    var _a;\n    if (!this._tokenizationStateStore) {\n      // nothing to do\n      return;\n    }\n    if (endLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n      // nothing to do\n      return;\n    }\n    if (startLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n      // tokenization has reached the viewport start...\n      this._tokenizationStateStore.updateTokensUntilLine(this._textModel, this._languageIdCodec, builder, endLineNumber);\n      return;\n    }\n    let state = this.guessStartState(startLineNumber);\n    const languageId = this._textModel.getLanguageId();\n    for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n      const text = this._textModel.getLineContent(lineNumber);\n      const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, state);\n      builder.add(lineNumber, r.tokens);\n      state = r.endState;\n    }\n    // We overrode the tokens. Because old states might get reused (thus stopping invalidation),\n    // we have to explicitly request the tokens for this range again.\n    (_a = this.backgroundTokenizer.value) === null || _a === void 0 ? void 0 : _a.requestTokens(startLineNumber, endLineNumber + 1);\n  }\n  guessStartState(lineNumber) {\n    let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(lineNumber);\n    const likelyRelevantLines = [];\n    let initialState = null;\n    for (let i = lineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n      const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n      // Ignore lines full of whitespace\n      if (newNonWhitespaceIndex === 0) {\n        continue;\n      }\n      if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n        likelyRelevantLines.push(this._textModel.getLineContent(i));\n        nonWhitespaceColumn = newNonWhitespaceIndex;\n        initialState = this._tokenizationStateStore.getBeginState(i - 1);\n        if (initialState) {\n          break;\n        }\n      }\n    }\n    if (!initialState) {\n      initialState = this._tokenizationStateStore.initialState;\n    }\n    likelyRelevantLines.reverse();\n    const languageId = this._textModel.getLanguageId();\n    let state = initialState;\n    for (const line of likelyRelevantLines) {\n      const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, line, false, state);\n      state = r.endState;\n    }\n    return state;\n  }\n}\nfunction initializeTokenization(textModel, tokenizationPart) {\n  if (textModel.isTooLargeForTokenization()) {\n    return [null, null];\n  }\n  const tokenizationSupport = TokenizationRegistry.get(tokenizationPart.getLanguageId());\n  if (!tokenizationSupport) {\n    return [null, null];\n  }\n  let initialState;\n  try {\n    initialState = tokenizationSupport.getInitialState();\n  } catch (e) {\n    onUnexpectedError(e);\n    return [null, null];\n  }\n  return [tokenizationSupport, initialState];\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n  let r = null;\n  if (tokenizationSupport) {\n    try {\n      r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n    } catch (e) {\n      onUnexpectedError(e);\n    }\n  }\n  if (!r) {\n    r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n  }\n  LineTokens.convertToEndOffset(r.tokens, text.length);\n  return r;\n}\nclass DefaultBackgroundTokenizer {\n  constructor(_textModel, _stateStore, _backgroundTokenStore, _languageIdCodec) {\n    this._textModel = _textModel;\n    this._stateStore = _stateStore;\n    this._backgroundTokenStore = _backgroundTokenStore;\n    this._languageIdCodec = _languageIdCodec;\n    this._isDisposed = false;\n    this._isScheduled = false;\n  }\n  dispose() {\n    this._isDisposed = true;\n  }\n  handleChanges() {\n    this._beginBackgroundTokenization();\n  }\n  _beginBackgroundTokenization() {\n    if (this._isScheduled || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n      return;\n    }\n    this._isScheduled = true;\n    runWhenIdle(deadline => {\n      this._isScheduled = false;\n      this._backgroundTokenizeWithDeadline(deadline);\n    });\n  }\n  /**\n   * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n   */\n  _backgroundTokenizeWithDeadline(deadline) {\n    // Read the time remaining from the `deadline` immediately because it is unclear\n    // if the `deadline` object will be valid after execution leaves this function.\n    const endTime = Date.now() + deadline.timeRemaining();\n    const execute = () => {\n      if (this._isDisposed || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n        // disposed in the meantime or detached or finished\n        return;\n      }\n      this._backgroundTokenizeForAtLeast1ms();\n      if (Date.now() < endTime) {\n        // There is still time before reaching the deadline, so yield to the browser and then\n        // continue execution\n        setTimeout0(execute);\n      } else {\n        // The deadline has been reached, so schedule a new idle callback if necessary\n        this._beginBackgroundTokenization();\n      }\n    };\n    execute();\n  }\n  /**\n   * Tokenize for at least 1ms.\n   */\n  _backgroundTokenizeForAtLeast1ms() {\n    const lineCount = this._textModel.getLineCount();\n    const builder = new ContiguousMultilineTokensBuilder();\n    const sw = StopWatch.create(false);\n    do {\n      if (sw.elapsed() > 1) {\n        // the comparison is intentionally > 1 and not >= 1 to ensure that\n        // a full millisecond has elapsed, given how microseconds are rounded\n        // to milliseconds\n        break;\n      }\n      const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n      if (tokenizedLineNumber >= lineCount) {\n        break;\n      }\n    } while (this._hasLinesToTokenize());\n    this._backgroundTokenStore.setTokens(builder.finalize());\n    this.checkFinished();\n  }\n  _hasLinesToTokenize() {\n    if (!this._stateStore) {\n      return false;\n    }\n    return this._stateStore.invalidLineStartIndex < this._textModel.getLineCount();\n  }\n  _tokenizeOneInvalidLine(builder) {\n    if (!this._stateStore || !this._hasLinesToTokenize()) {\n      return this._textModel.getLineCount() + 1;\n    }\n    const lineNumber = this._stateStore.invalidLineStartIndex + 1;\n    this._stateStore.updateTokensUntilLine(this._textModel, this._languageIdCodec, builder, lineNumber);\n    return lineNumber;\n  }\n  checkFinished() {\n    if (this._isDisposed) {\n      return;\n    }\n    if (this._stateStore.isTokenizationComplete(this._textModel)) {\n      this._backgroundTokenStore.backgroundTokenizationFinished();\n    }\n  }\n  requestTokens(startLineNumber, endLineNumberExclusive) {\n    for (let lineNumber = startLineNumber; lineNumber < endLineNumberExclusive; lineNumber++) {\n      this._stateStore.markMustBeTokenized(lineNumber - 1);\n    }\n  }\n}","map":{"version":3,"names":["arrays","runWhenIdle","BugIndicatingError","onUnexpectedError","Disposable","MutableDisposable","setTimeout0","StopWatch","countEOL","TokenizationRegistry","nullTokenizeEncoded","ContiguousMultilineTokensBuilder","LineTokens","ContiguousGrowingArray","constructor","_default","_store","get","index","length","set","value","delete","deleteIndex","deleteCount","splice","insert","insertIndex","insertCount","arr","i","arrayInsert","TokenizationStateStore","invalidLineStartIndex","_firstLineNeedsTokenization","tokenizationSupport","initialState","_lineBeginState","_lineNeedsTokenization","markMustBeTokenized","lineIndex","Math","min","getBeginState","setEndState","linesLength","endState","previousEndState","equals","applyEdits","range","eolCount","startLineNumber","endLineNumber","updateTokensUntilLine","textModel","languageIdCodec","builder","lineNumber","languageId","getLanguageId","getLineCount","endLineIndex","text","getLineContent","lineStartState","r","safeTokenize","add","tokens","isTokenizationComplete","TextModelTokenization","_textModel","_tokenizationPart","_languageIdCodec","_tokenizationStateStore","_defaultBackgroundTokenizer","backgroundTokenizer","_register","onDidChange","e","changedLanguages","indexOf","_resetTokenizationState","clearTokens","handleDidChangeContent","_a","isFlush","len","changes","change","handleChanges","handleDidChangeAttached","handleDidChangeLanguage","initializeTokenization","clear","b","setTokens","backgroundTokenizationFinished","handleBackgroundTokenizationFinished","state","_b","undefined","createBackgroundTokenizer","DefaultBackgroundTokenizer","tokenizeViewport","_heuristicallyTokenizeViewport","finalize","checkFinished","reset","forceTokenization","getTokenTypeIfInsertingCharacter","position","character","lineContent","substring","column","lineTokens","getCount","tokenIndex","findTokenIndexAtOffset","getStandardTokenType","tokenizeLineWithEdit","newText","curLineContent","newLineContent","getLanguageIdAtPosition","result","isCheapToTokenize","firstInvalidLineNumber","getLineLength","guessStartState","requestTokens","nonWhitespaceColumn","getLineFirstNonWhitespaceColumn","likelyRelevantLines","newNonWhitespaceIndex","push","reverse","line","tokenizationPart","isTooLargeForTokenization","getInitialState","hasEOL","tokenizeEncoded","clone","encodeLanguageId","convertToEndOffset","_stateStore","_backgroundTokenStore","_isDisposed","_isScheduled","dispose","_beginBackgroundTokenization","isAttachedToEditor","_hasLinesToTokenize","deadline","_backgroundTokenizeWithDeadline","endTime","Date","now","timeRemaining","execute","_backgroundTokenizeForAtLeast1ms","lineCount","sw","create","elapsed","tokenizedLineNumber","_tokenizeOneInvalidLine","endLineNumberExclusive"],"sources":["/Users/cadany/WebstormProjects/monaco/node_modules/monaco-editor/esm/vs/editor/common/model/textModelTokens.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { runWhenIdle } from '../../../base/common/async.js';\nimport { BugIndicatingError, onUnexpectedError } from '../../../base/common/errors.js';\nimport { Disposable, MutableDisposable } from '../../../base/common/lifecycle.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { TokenizationRegistry } from '../languages.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\n/**\n * An array that avoids being sparse by always\n * filling up unused indices with a default value.\n */\nexport class ContiguousGrowingArray {\n    constructor(_default) {\n        this._default = _default;\n        this._store = [];\n    }\n    get(index) {\n        if (index < this._store.length) {\n            return this._store[index];\n        }\n        return this._default;\n    }\n    set(index, value) {\n        while (index >= this._store.length) {\n            this._store[this._store.length] = this._default;\n        }\n        this._store[index] = value;\n    }\n    // TODO have `replace` instead of `delete` and `insert`\n    delete(deleteIndex, deleteCount) {\n        if (deleteCount === 0 || deleteIndex >= this._store.length) {\n            return;\n        }\n        this._store.splice(deleteIndex, deleteCount);\n    }\n    insert(insertIndex, insertCount) {\n        if (insertCount === 0 || insertIndex >= this._store.length) {\n            return;\n        }\n        const arr = [];\n        for (let i = 0; i < insertCount; i++) {\n            arr[i] = this._default;\n        }\n        this._store = arrays.arrayInsert(this._store, insertIndex, arr);\n    }\n}\n/**\n * Stores the states at the start of each line and keeps track of which lines\n * must be re-tokenized. Also uses state equality to quickly validate lines\n * that don't need to be re-tokenized.\n *\n * For example, when typing on a line, the line gets marked as needing to be tokenized.\n * Once the line is tokenized, the end state is checked for equality against the begin\n * state of the next line. If the states are equal, tokenization doesn't need to run\n * again over the rest of the file. If the states are not equal, the next line gets marked\n * as needing to be tokenized.\n */\nexport class TokenizationStateStore {\n    get invalidLineStartIndex() {\n        return this._firstLineNeedsTokenization;\n    }\n    constructor(tokenizationSupport, initialState) {\n        this.tokenizationSupport = tokenizationSupport;\n        this.initialState = initialState;\n        /**\n         * `lineBeginState[i]` contains the begin state used to tokenize line number `i + 1`.\n         */\n        this._lineBeginState = new ContiguousGrowingArray(null);\n        /**\n         * `lineNeedsTokenization[i]` describes if line number `i + 1` needs to be tokenized.\n         */\n        this._lineNeedsTokenization = new ContiguousGrowingArray(true);\n        this._firstLineNeedsTokenization = 0;\n        this._lineBeginState.set(0, this.initialState);\n    }\n    markMustBeTokenized(lineIndex) {\n        this._lineNeedsTokenization.set(lineIndex, true);\n        this._firstLineNeedsTokenization = Math.min(this._firstLineNeedsTokenization, lineIndex);\n    }\n    getBeginState(lineIndex) {\n        return this._lineBeginState.get(lineIndex);\n    }\n    setEndState(linesLength, lineIndex, endState) {\n        this._lineNeedsTokenization.set(lineIndex, false);\n        this._firstLineNeedsTokenization = lineIndex + 1;\n        // Check if this was the last line\n        if (lineIndex === linesLength - 1) {\n            return false;\n        }\n        // Check if the end state has changed\n        const previousEndState = this._lineBeginState.get(lineIndex + 1);\n        if (previousEndState === null || !endState.equals(previousEndState)) {\n            this._lineBeginState.set(lineIndex + 1, endState);\n            this.markMustBeTokenized(lineIndex + 1);\n            return true;\n        }\n        // Perhaps we can skip tokenizing some lines...\n        let i = lineIndex + 1;\n        while (i < linesLength) {\n            if (this._lineNeedsTokenization.get(i)) {\n                break;\n            }\n            i++;\n        }\n        this._firstLineNeedsTokenization = i;\n        return false;\n    }\n    applyEdits(range, eolCount) {\n        this.markMustBeTokenized(range.startLineNumber - 1);\n        this._lineBeginState.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n        this._lineNeedsTokenization.delete(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n        this._lineBeginState.insert(range.startLineNumber, eolCount);\n        this._lineNeedsTokenization.insert(range.startLineNumber, eolCount);\n    }\n    updateTokensUntilLine(textModel, languageIdCodec, builder, lineNumber) {\n        const languageId = textModel.getLanguageId();\n        const linesLength = textModel.getLineCount();\n        const endLineIndex = lineNumber - 1;\n        // Validate all states up to and including endLineIndex\n        for (let lineIndex = this.invalidLineStartIndex; lineIndex <= endLineIndex; lineIndex++) {\n            const text = textModel.getLineContent(lineIndex + 1);\n            const lineStartState = this.getBeginState(lineIndex);\n            const r = safeTokenize(languageIdCodec, languageId, this.tokenizationSupport, text, true, lineStartState);\n            builder.add(lineIndex + 1, r.tokens);\n            this.setEndState(linesLength, lineIndex, r.endState);\n            lineIndex = this.invalidLineStartIndex - 1; // -1 because the outer loop increments it\n        }\n    }\n    isTokenizationComplete(textModel) {\n        return this.invalidLineStartIndex >= textModel.getLineCount();\n    }\n}\nexport class TextModelTokenization extends Disposable {\n    constructor(_textModel, _tokenizationPart, _languageIdCodec) {\n        super();\n        this._textModel = _textModel;\n        this._tokenizationPart = _tokenizationPart;\n        this._languageIdCodec = _languageIdCodec;\n        this._tokenizationStateStore = null;\n        this._defaultBackgroundTokenizer = null;\n        this.backgroundTokenizer = this._register(new MutableDisposable());\n        this._register(TokenizationRegistry.onDidChange((e) => {\n            const languageId = this._textModel.getLanguageId();\n            if (e.changedLanguages.indexOf(languageId) === -1) {\n                return;\n            }\n            this._resetTokenizationState();\n            this._tokenizationPart.clearTokens();\n        }));\n        this._resetTokenizationState();\n    }\n    handleDidChangeContent(e) {\n        var _a;\n        if (e.isFlush) {\n            this._resetTokenizationState();\n            return;\n        }\n        if (this._tokenizationStateStore) {\n            for (let i = 0, len = e.changes.length; i < len; i++) {\n                const change = e.changes[i];\n                const [eolCount] = countEOL(change.text);\n                this._tokenizationStateStore.applyEdits(change.range, eolCount);\n            }\n        }\n        (_a = this._defaultBackgroundTokenizer) === null || _a === void 0 ? void 0 : _a.handleChanges();\n    }\n    handleDidChangeAttached() {\n        var _a;\n        (_a = this._defaultBackgroundTokenizer) === null || _a === void 0 ? void 0 : _a.handleChanges();\n    }\n    handleDidChangeLanguage(e) {\n        this._resetTokenizationState();\n        this._tokenizationPart.clearTokens();\n    }\n    _resetTokenizationState() {\n        const [tokenizationSupport, initialState] = initializeTokenization(this._textModel, this._tokenizationPart);\n        if (tokenizationSupport && initialState) {\n            this._tokenizationStateStore = new TokenizationStateStore(tokenizationSupport, initialState);\n        }\n        else {\n            this._tokenizationStateStore = null;\n        }\n        this.backgroundTokenizer.clear();\n        this._defaultBackgroundTokenizer = null;\n        if (this._tokenizationStateStore) {\n            const b = {\n                setTokens: (tokens) => {\n                    this._tokenizationPart.setTokens(tokens);\n                },\n                backgroundTokenizationFinished: () => {\n                    this._tokenizationPart.handleBackgroundTokenizationFinished();\n                },\n                setEndState: (lineNumber, state) => {\n                    var _a, _b;\n                    if (!state) {\n                        throw new BugIndicatingError();\n                    }\n                    const invalidLineStartIndex = (_a = this._tokenizationStateStore) === null || _a === void 0 ? void 0 : _a.invalidLineStartIndex;\n                    if (invalidLineStartIndex !== undefined && lineNumber - 1 >= invalidLineStartIndex) {\n                        // Don't accept states for definitely valid states\n                        (_b = this._tokenizationStateStore) === null || _b === void 0 ? void 0 : _b.setEndState(this._textModel.getLineCount(), lineNumber - 1, state);\n                    }\n                },\n            };\n            if (tokenizationSupport && tokenizationSupport.createBackgroundTokenizer) {\n                this.backgroundTokenizer.value = tokenizationSupport.createBackgroundTokenizer(this._textModel, b);\n            }\n            if (!this.backgroundTokenizer.value) {\n                this.backgroundTokenizer.value = this._defaultBackgroundTokenizer =\n                    new DefaultBackgroundTokenizer(this._textModel, this._tokenizationStateStore, b, this._languageIdCodec);\n                this._defaultBackgroundTokenizer.handleChanges();\n            }\n        }\n    }\n    tokenizeViewport(startLineNumber, endLineNumber) {\n        var _a;\n        const builder = new ContiguousMultilineTokensBuilder();\n        this._heuristicallyTokenizeViewport(builder, startLineNumber, endLineNumber);\n        this._tokenizationPart.setTokens(builder.finalize());\n        (_a = this._defaultBackgroundTokenizer) === null || _a === void 0 ? void 0 : _a.checkFinished();\n    }\n    reset() {\n        this._resetTokenizationState();\n        this._tokenizationPart.clearTokens();\n    }\n    forceTokenization(lineNumber) {\n        var _a, _b;\n        const builder = new ContiguousMultilineTokensBuilder();\n        (_a = this._tokenizationStateStore) === null || _a === void 0 ? void 0 : _a.updateTokensUntilLine(this._textModel, this._languageIdCodec, builder, lineNumber);\n        this._tokenizationPart.setTokens(builder.finalize());\n        (_b = this._defaultBackgroundTokenizer) === null || _b === void 0 ? void 0 : _b.checkFinished();\n    }\n    getTokenTypeIfInsertingCharacter(position, character) {\n        if (!this._tokenizationStateStore) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        this.forceTokenization(position.lineNumber);\n        const lineStartState = this._tokenizationStateStore.getBeginState(position.lineNumber - 1);\n        if (!lineStartState) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const lineContent = this._textModel.getLineContent(position.lineNumber);\n        // Create the text as if `character` was inserted\n        const text = (lineContent.substring(0, position.column - 1)\n            + character\n            + lineContent.substring(position.column - 1));\n        const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, lineStartState);\n        const lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n        if (lineTokens.getCount() === 0) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n        return lineTokens.getStandardTokenType(tokenIndex);\n    }\n    tokenizeLineWithEdit(position, length, newText) {\n        const lineNumber = position.lineNumber;\n        const column = position.column;\n        if (!this._tokenizationStateStore) {\n            return null;\n        }\n        this.forceTokenization(lineNumber);\n        const lineStartState = this._tokenizationStateStore.getBeginState(lineNumber - 1);\n        if (!lineStartState) {\n            return null;\n        }\n        const curLineContent = this._textModel.getLineContent(lineNumber);\n        const newLineContent = curLineContent.substring(0, column - 1)\n            + newText + curLineContent.substring(column - 1 + length);\n        const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n        const result = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, newLineContent, true, lineStartState);\n        const lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n        return lineTokens;\n    }\n    isCheapToTokenize(lineNumber) {\n        if (!this._tokenizationStateStore) {\n            return true;\n        }\n        const firstInvalidLineNumber = this._tokenizationStateStore.invalidLineStartIndex + 1;\n        if (lineNumber > firstInvalidLineNumber) {\n            return false;\n        }\n        if (lineNumber < firstInvalidLineNumber) {\n            return true;\n        }\n        if (this._textModel.getLineLength(lineNumber) < 2048 /* Constants.CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n            return true;\n        }\n        return false;\n    }\n    /**\n     * The result is not cached.\n     */\n    _heuristicallyTokenizeViewport(builder, startLineNumber, endLineNumber) {\n        var _a;\n        if (!this._tokenizationStateStore) {\n            // nothing to do\n            return;\n        }\n        if (endLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n            // nothing to do\n            return;\n        }\n        if (startLineNumber <= this._tokenizationStateStore.invalidLineStartIndex) {\n            // tokenization has reached the viewport start...\n            this._tokenizationStateStore.updateTokensUntilLine(this._textModel, this._languageIdCodec, builder, endLineNumber);\n            return;\n        }\n        let state = this.guessStartState(startLineNumber);\n        const languageId = this._textModel.getLanguageId();\n        for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n            const text = this._textModel.getLineContent(lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, text, true, state);\n            builder.add(lineNumber, r.tokens);\n            state = r.endState;\n        }\n        // We overrode the tokens. Because old states might get reused (thus stopping invalidation),\n        // we have to explicitly request the tokens for this range again.\n        (_a = this.backgroundTokenizer.value) === null || _a === void 0 ? void 0 : _a.requestTokens(startLineNumber, endLineNumber + 1);\n    }\n    guessStartState(lineNumber) {\n        let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(lineNumber);\n        const likelyRelevantLines = [];\n        let initialState = null;\n        for (let i = lineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n            const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n            // Ignore lines full of whitespace\n            if (newNonWhitespaceIndex === 0) {\n                continue;\n            }\n            if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n                likelyRelevantLines.push(this._textModel.getLineContent(i));\n                nonWhitespaceColumn = newNonWhitespaceIndex;\n                initialState = this._tokenizationStateStore.getBeginState(i - 1);\n                if (initialState) {\n                    break;\n                }\n            }\n        }\n        if (!initialState) {\n            initialState = this._tokenizationStateStore.initialState;\n        }\n        likelyRelevantLines.reverse();\n        const languageId = this._textModel.getLanguageId();\n        let state = initialState;\n        for (const line of likelyRelevantLines) {\n            const r = safeTokenize(this._languageIdCodec, languageId, this._tokenizationStateStore.tokenizationSupport, line, false, state);\n            state = r.endState;\n        }\n        return state;\n    }\n}\nfunction initializeTokenization(textModel, tokenizationPart) {\n    if (textModel.isTooLargeForTokenization()) {\n        return [null, null];\n    }\n    const tokenizationSupport = TokenizationRegistry.get(tokenizationPart.getLanguageId());\n    if (!tokenizationSupport) {\n        return [null, null];\n    }\n    let initialState;\n    try {\n        initialState = tokenizationSupport.getInitialState();\n    }\n    catch (e) {\n        onUnexpectedError(e);\n        return [null, null];\n    }\n    return [tokenizationSupport, initialState];\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n    let r = null;\n    if (tokenizationSupport) {\n        try {\n            r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n        }\n        catch (e) {\n            onUnexpectedError(e);\n        }\n    }\n    if (!r) {\n        r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n    }\n    LineTokens.convertToEndOffset(r.tokens, text.length);\n    return r;\n}\nclass DefaultBackgroundTokenizer {\n    constructor(_textModel, _stateStore, _backgroundTokenStore, _languageIdCodec) {\n        this._textModel = _textModel;\n        this._stateStore = _stateStore;\n        this._backgroundTokenStore = _backgroundTokenStore;\n        this._languageIdCodec = _languageIdCodec;\n        this._isDisposed = false;\n        this._isScheduled = false;\n    }\n    dispose() {\n        this._isDisposed = true;\n    }\n    handleChanges() {\n        this._beginBackgroundTokenization();\n    }\n    _beginBackgroundTokenization() {\n        if (this._isScheduled || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n            return;\n        }\n        this._isScheduled = true;\n        runWhenIdle((deadline) => {\n            this._isScheduled = false;\n            this._backgroundTokenizeWithDeadline(deadline);\n        });\n    }\n    /**\n     * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n     */\n    _backgroundTokenizeWithDeadline(deadline) {\n        // Read the time remaining from the `deadline` immediately because it is unclear\n        // if the `deadline` object will be valid after execution leaves this function.\n        const endTime = Date.now() + deadline.timeRemaining();\n        const execute = () => {\n            if (this._isDisposed || !this._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n                // disposed in the meantime or detached or finished\n                return;\n            }\n            this._backgroundTokenizeForAtLeast1ms();\n            if (Date.now() < endTime) {\n                // There is still time before reaching the deadline, so yield to the browser and then\n                // continue execution\n                setTimeout0(execute);\n            }\n            else {\n                // The deadline has been reached, so schedule a new idle callback if necessary\n                this._beginBackgroundTokenization();\n            }\n        };\n        execute();\n    }\n    /**\n     * Tokenize for at least 1ms.\n     */\n    _backgroundTokenizeForAtLeast1ms() {\n        const lineCount = this._textModel.getLineCount();\n        const builder = new ContiguousMultilineTokensBuilder();\n        const sw = StopWatch.create(false);\n        do {\n            if (sw.elapsed() > 1) {\n                // the comparison is intentionally > 1 and not >= 1 to ensure that\n                // a full millisecond has elapsed, given how microseconds are rounded\n                // to milliseconds\n                break;\n            }\n            const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n            if (tokenizedLineNumber >= lineCount) {\n                break;\n            }\n        } while (this._hasLinesToTokenize());\n        this._backgroundTokenStore.setTokens(builder.finalize());\n        this.checkFinished();\n    }\n    _hasLinesToTokenize() {\n        if (!this._stateStore) {\n            return false;\n        }\n        return this._stateStore.invalidLineStartIndex < this._textModel.getLineCount();\n    }\n    _tokenizeOneInvalidLine(builder) {\n        if (!this._stateStore || !this._hasLinesToTokenize()) {\n            return this._textModel.getLineCount() + 1;\n        }\n        const lineNumber = this._stateStore.invalidLineStartIndex + 1;\n        this._stateStore.updateTokensUntilLine(this._textModel, this._languageIdCodec, builder, lineNumber);\n        return lineNumber;\n    }\n    checkFinished() {\n        if (this._isDisposed) {\n            return;\n        }\n        if (this._stateStore.isTokenizationComplete(this._textModel)) {\n            this._backgroundTokenStore.backgroundTokenizationFinished();\n        }\n    }\n    requestTokens(startLineNumber, endLineNumberExclusive) {\n        for (let lineNumber = startLineNumber; lineNumber < endLineNumberExclusive; lineNumber++) {\n            this._stateStore.markMustBeTokenized(lineNumber - 1);\n        }\n    }\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA,OAAO,KAAKA,MAAM,MAAM,gCAAgC;AACxD,SAASC,WAAW,QAAQ,+BAA+B;AAC3D,SAASC,kBAAkB,EAAEC,iBAAiB,QAAQ,gCAAgC;AACtF,SAASC,UAAU,EAAEC,iBAAiB,QAAQ,mCAAmC;AACjF,SAASC,WAAW,QAAQ,kCAAkC;AAC9D,SAASC,SAAS,QAAQ,mCAAmC;AAC7D,SAASC,QAAQ,QAAQ,uBAAuB;AAChD,SAASC,oBAAoB,QAAQ,iBAAiB;AACtD,SAASC,mBAAmB,QAAQ,8BAA8B;AAClE,SAASC,gCAAgC,QAAQ,+CAA+C;AAChG,SAASC,UAAU,QAAQ,yBAAyB;AACpD;AACA;AACA;AACA;AACA,OAAO,MAAMC,sBAAsB,CAAC;EAChCC,WAAWA,CAACC,QAAQ,EAAE;IAClB,IAAI,CAACA,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACC,MAAM,GAAG,EAAE;EACpB;EACAC,GAAGA,CAACC,KAAK,EAAE;IACP,IAAIA,KAAK,GAAG,IAAI,CAACF,MAAM,CAACG,MAAM,EAAE;MAC5B,OAAO,IAAI,CAACH,MAAM,CAACE,KAAK,CAAC;IAC7B;IACA,OAAO,IAAI,CAACH,QAAQ;EACxB;EACAK,GAAGA,CAACF,KAAK,EAAEG,KAAK,EAAE;IACd,OAAOH,KAAK,IAAI,IAAI,CAACF,MAAM,CAACG,MAAM,EAAE;MAChC,IAAI,CAACH,MAAM,CAAC,IAAI,CAACA,MAAM,CAACG,MAAM,CAAC,GAAG,IAAI,CAACJ,QAAQ;IACnD;IACA,IAAI,CAACC,MAAM,CAACE,KAAK,CAAC,GAAGG,KAAK;EAC9B;EACA;EACAC,MAAMA,CAACC,WAAW,EAAEC,WAAW,EAAE;IAC7B,IAAIA,WAAW,KAAK,CAAC,IAAID,WAAW,IAAI,IAAI,CAACP,MAAM,CAACG,MAAM,EAAE;MACxD;IACJ;IACA,IAAI,CAACH,MAAM,CAACS,MAAM,CAACF,WAAW,EAAEC,WAAW,CAAC;EAChD;EACAE,MAAMA,CAACC,WAAW,EAAEC,WAAW,EAAE;IAC7B,IAAIA,WAAW,KAAK,CAAC,IAAID,WAAW,IAAI,IAAI,CAACX,MAAM,CAACG,MAAM,EAAE;MACxD;IACJ;IACA,MAAMU,GAAG,GAAG,EAAE;IACd,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,WAAW,EAAEE,CAAC,EAAE,EAAE;MAClCD,GAAG,CAACC,CAAC,CAAC,GAAG,IAAI,CAACf,QAAQ;IAC1B;IACA,IAAI,CAACC,MAAM,GAAGhB,MAAM,CAAC+B,WAAW,CAAC,IAAI,CAACf,MAAM,EAAEW,WAAW,EAAEE,GAAG,CAAC;EACnE;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMG,sBAAsB,CAAC;EAChC,IAAIC,qBAAqBA,CAAA,EAAG;IACxB,OAAO,IAAI,CAACC,2BAA2B;EAC3C;EACApB,WAAWA,CAACqB,mBAAmB,EAAEC,YAAY,EAAE;IAC3C,IAAI,CAACD,mBAAmB,GAAGA,mBAAmB;IAC9C,IAAI,CAACC,YAAY,GAAGA,YAAY;IAChC;AACR;AACA;IACQ,IAAI,CAACC,eAAe,GAAG,IAAIxB,sBAAsB,CAAC,IAAI,CAAC;IACvD;AACR;AACA;IACQ,IAAI,CAACyB,sBAAsB,GAAG,IAAIzB,sBAAsB,CAAC,IAAI,CAAC;IAC9D,IAAI,CAACqB,2BAA2B,GAAG,CAAC;IACpC,IAAI,CAACG,eAAe,CAACjB,GAAG,CAAC,CAAC,EAAE,IAAI,CAACgB,YAAY,CAAC;EAClD;EACAG,mBAAmBA,CAACC,SAAS,EAAE;IAC3B,IAAI,CAACF,sBAAsB,CAAClB,GAAG,CAACoB,SAAS,EAAE,IAAI,CAAC;IAChD,IAAI,CAACN,2BAA2B,GAAGO,IAAI,CAACC,GAAG,CAAC,IAAI,CAACR,2BAA2B,EAAEM,SAAS,CAAC;EAC5F;EACAG,aAAaA,CAACH,SAAS,EAAE;IACrB,OAAO,IAAI,CAACH,eAAe,CAACpB,GAAG,CAACuB,SAAS,CAAC;EAC9C;EACAI,WAAWA,CAACC,WAAW,EAAEL,SAAS,EAAEM,QAAQ,EAAE;IAC1C,IAAI,CAACR,sBAAsB,CAAClB,GAAG,CAACoB,SAAS,EAAE,KAAK,CAAC;IACjD,IAAI,CAACN,2BAA2B,GAAGM,SAAS,GAAG,CAAC;IAChD;IACA,IAAIA,SAAS,KAAKK,WAAW,GAAG,CAAC,EAAE;MAC/B,OAAO,KAAK;IAChB;IACA;IACA,MAAME,gBAAgB,GAAG,IAAI,CAACV,eAAe,CAACpB,GAAG,CAACuB,SAAS,GAAG,CAAC,CAAC;IAChE,IAAIO,gBAAgB,KAAK,IAAI,IAAI,CAACD,QAAQ,CAACE,MAAM,CAACD,gBAAgB,CAAC,EAAE;MACjE,IAAI,CAACV,eAAe,CAACjB,GAAG,CAACoB,SAAS,GAAG,CAAC,EAAEM,QAAQ,CAAC;MACjD,IAAI,CAACP,mBAAmB,CAACC,SAAS,GAAG,CAAC,CAAC;MACvC,OAAO,IAAI;IACf;IACA;IACA,IAAIV,CAAC,GAAGU,SAAS,GAAG,CAAC;IACrB,OAAOV,CAAC,GAAGe,WAAW,EAAE;MACpB,IAAI,IAAI,CAACP,sBAAsB,CAACrB,GAAG,CAACa,CAAC,CAAC,EAAE;QACpC;MACJ;MACAA,CAAC,EAAE;IACP;IACA,IAAI,CAACI,2BAA2B,GAAGJ,CAAC;IACpC,OAAO,KAAK;EAChB;EACAmB,UAAUA,CAACC,KAAK,EAAEC,QAAQ,EAAE;IACxB,IAAI,CAACZ,mBAAmB,CAACW,KAAK,CAACE,eAAe,GAAG,CAAC,CAAC;IACnD,IAAI,CAACf,eAAe,CAACf,MAAM,CAAC4B,KAAK,CAACE,eAAe,EAAEF,KAAK,CAACG,aAAa,GAAGH,KAAK,CAACE,eAAe,CAAC;IAC/F,IAAI,CAACd,sBAAsB,CAAChB,MAAM,CAAC4B,KAAK,CAACE,eAAe,EAAEF,KAAK,CAACG,aAAa,GAAGH,KAAK,CAACE,eAAe,CAAC;IACtG,IAAI,CAACf,eAAe,CAACX,MAAM,CAACwB,KAAK,CAACE,eAAe,EAAED,QAAQ,CAAC;IAC5D,IAAI,CAACb,sBAAsB,CAACZ,MAAM,CAACwB,KAAK,CAACE,eAAe,EAAED,QAAQ,CAAC;EACvE;EACAG,qBAAqBA,CAACC,SAAS,EAAEC,eAAe,EAAEC,OAAO,EAAEC,UAAU,EAAE;IACnE,MAAMC,UAAU,GAAGJ,SAAS,CAACK,aAAa,EAAE;IAC5C,MAAMf,WAAW,GAAGU,SAAS,CAACM,YAAY,EAAE;IAC5C,MAAMC,YAAY,GAAGJ,UAAU,GAAG,CAAC;IACnC;IACA,KAAK,IAAIlB,SAAS,GAAG,IAAI,CAACP,qBAAqB,EAAEO,SAAS,IAAIsB,YAAY,EAAEtB,SAAS,EAAE,EAAE;MACrF,MAAMuB,IAAI,GAAGR,SAAS,CAACS,cAAc,CAACxB,SAAS,GAAG,CAAC,CAAC;MACpD,MAAMyB,cAAc,GAAG,IAAI,CAACtB,aAAa,CAACH,SAAS,CAAC;MACpD,MAAM0B,CAAC,GAAGC,YAAY,CAACX,eAAe,EAAEG,UAAU,EAAE,IAAI,CAACxB,mBAAmB,EAAE4B,IAAI,EAAE,IAAI,EAAEE,cAAc,CAAC;MACzGR,OAAO,CAACW,GAAG,CAAC5B,SAAS,GAAG,CAAC,EAAE0B,CAAC,CAACG,MAAM,CAAC;MACpC,IAAI,CAACzB,WAAW,CAACC,WAAW,EAAEL,SAAS,EAAE0B,CAAC,CAACpB,QAAQ,CAAC;MACpDN,SAAS,GAAG,IAAI,CAACP,qBAAqB,GAAG,CAAC,CAAC,CAAC;IAChD;EACJ;;EACAqC,sBAAsBA,CAACf,SAAS,EAAE;IAC9B,OAAO,IAAI,CAACtB,qBAAqB,IAAIsB,SAAS,CAACM,YAAY,EAAE;EACjE;AACJ;AACA,OAAO,MAAMU,qBAAqB,SAASnE,UAAU,CAAC;EAClDU,WAAWA,CAAC0D,UAAU,EAAEC,iBAAiB,EAAEC,gBAAgB,EAAE;IACzD,KAAK,EAAE;IACP,IAAI,CAACF,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,iBAAiB,GAAGA,iBAAiB;IAC1C,IAAI,CAACC,gBAAgB,GAAGA,gBAAgB;IACxC,IAAI,CAACC,uBAAuB,GAAG,IAAI;IACnC,IAAI,CAACC,2BAA2B,GAAG,IAAI;IACvC,IAAI,CAACC,mBAAmB,GAAG,IAAI,CAACC,SAAS,CAAC,IAAIzE,iBAAiB,EAAE,CAAC;IAClE,IAAI,CAACyE,SAAS,CAACrE,oBAAoB,CAACsE,WAAW,CAAEC,CAAC,IAAK;MACnD,MAAMrB,UAAU,GAAG,IAAI,CAACa,UAAU,CAACZ,aAAa,EAAE;MAClD,IAAIoB,CAAC,CAACC,gBAAgB,CAACC,OAAO,CAACvB,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE;QAC/C;MACJ;MACA,IAAI,CAACwB,uBAAuB,EAAE;MAC9B,IAAI,CAACV,iBAAiB,CAACW,WAAW,EAAE;IACxC,CAAC,CAAC,CAAC;IACH,IAAI,CAACD,uBAAuB,EAAE;EAClC;EACAE,sBAAsBA,CAACL,CAAC,EAAE;IACtB,IAAIM,EAAE;IACN,IAAIN,CAAC,CAACO,OAAO,EAAE;MACX,IAAI,CAACJ,uBAAuB,EAAE;MAC9B;IACJ;IACA,IAAI,IAAI,CAACR,uBAAuB,EAAE;MAC9B,KAAK,IAAI7C,CAAC,GAAG,CAAC,EAAE0D,GAAG,GAAGR,CAAC,CAACS,OAAO,CAACtE,MAAM,EAAEW,CAAC,GAAG0D,GAAG,EAAE1D,CAAC,EAAE,EAAE;QAClD,MAAM4D,MAAM,GAAGV,CAAC,CAACS,OAAO,CAAC3D,CAAC,CAAC;QAC3B,MAAM,CAACqB,QAAQ,CAAC,GAAG3C,QAAQ,CAACkF,MAAM,CAAC3B,IAAI,CAAC;QACxC,IAAI,CAACY,uBAAuB,CAAC1B,UAAU,CAACyC,MAAM,CAACxC,KAAK,EAAEC,QAAQ,CAAC;MACnE;IACJ;IACA,CAACmC,EAAE,GAAG,IAAI,CAACV,2BAA2B,MAAM,IAAI,IAAIU,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACK,aAAa,EAAE;EACnG;EACAC,uBAAuBA,CAAA,EAAG;IACtB,IAAIN,EAAE;IACN,CAACA,EAAE,GAAG,IAAI,CAACV,2BAA2B,MAAM,IAAI,IAAIU,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACK,aAAa,EAAE;EACnG;EACAE,uBAAuBA,CAACb,CAAC,EAAE;IACvB,IAAI,CAACG,uBAAuB,EAAE;IAC9B,IAAI,CAACV,iBAAiB,CAACW,WAAW,EAAE;EACxC;EACAD,uBAAuBA,CAAA,EAAG;IACtB,MAAM,CAAChD,mBAAmB,EAAEC,YAAY,CAAC,GAAG0D,sBAAsB,CAAC,IAAI,CAACtB,UAAU,EAAE,IAAI,CAACC,iBAAiB,CAAC;IAC3G,IAAItC,mBAAmB,IAAIC,YAAY,EAAE;MACrC,IAAI,CAACuC,uBAAuB,GAAG,IAAI3C,sBAAsB,CAACG,mBAAmB,EAAEC,YAAY,CAAC;IAChG,CAAC,MACI;MACD,IAAI,CAACuC,uBAAuB,GAAG,IAAI;IACvC;IACA,IAAI,CAACE,mBAAmB,CAACkB,KAAK,EAAE;IAChC,IAAI,CAACnB,2BAA2B,GAAG,IAAI;IACvC,IAAI,IAAI,CAACD,uBAAuB,EAAE;MAC9B,MAAMqB,CAAC,GAAG;QACNC,SAAS,EAAG5B,MAAM,IAAK;UACnB,IAAI,CAACI,iBAAiB,CAACwB,SAAS,CAAC5B,MAAM,CAAC;QAC5C,CAAC;QACD6B,8BAA8B,EAAEA,CAAA,KAAM;UAClC,IAAI,CAACzB,iBAAiB,CAAC0B,oCAAoC,EAAE;QACjE,CAAC;QACDvD,WAAW,EAAEA,CAACc,UAAU,EAAE0C,KAAK,KAAK;UAChC,IAAId,EAAE,EAAEe,EAAE;UACV,IAAI,CAACD,KAAK,EAAE;YACR,MAAM,IAAIlG,kBAAkB,EAAE;UAClC;UACA,MAAM+B,qBAAqB,GAAG,CAACqD,EAAE,GAAG,IAAI,CAACX,uBAAuB,MAAM,IAAI,IAAIW,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACrD,qBAAqB;UAC/H,IAAIA,qBAAqB,KAAKqE,SAAS,IAAI5C,UAAU,GAAG,CAAC,IAAIzB,qBAAqB,EAAE;YAChF;YACA,CAACoE,EAAE,GAAG,IAAI,CAAC1B,uBAAuB,MAAM,IAAI,IAAI0B,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACzD,WAAW,CAAC,IAAI,CAAC4B,UAAU,CAACX,YAAY,EAAE,EAAEH,UAAU,GAAG,CAAC,EAAE0C,KAAK,CAAC;UAClJ;QACJ;MACJ,CAAC;MACD,IAAIjE,mBAAmB,IAAIA,mBAAmB,CAACoE,yBAAyB,EAAE;QACtE,IAAI,CAAC1B,mBAAmB,CAACxD,KAAK,GAAGc,mBAAmB,CAACoE,yBAAyB,CAAC,IAAI,CAAC/B,UAAU,EAAEwB,CAAC,CAAC;MACtG;MACA,IAAI,CAAC,IAAI,CAACnB,mBAAmB,CAACxD,KAAK,EAAE;QACjC,IAAI,CAACwD,mBAAmB,CAACxD,KAAK,GAAG,IAAI,CAACuD,2BAA2B,GAC7D,IAAI4B,0BAA0B,CAAC,IAAI,CAAChC,UAAU,EAAE,IAAI,CAACG,uBAAuB,EAAEqB,CAAC,EAAE,IAAI,CAACtB,gBAAgB,CAAC;QAC3G,IAAI,CAACE,2BAA2B,CAACe,aAAa,EAAE;MACpD;IACJ;EACJ;EACAc,gBAAgBA,CAACrD,eAAe,EAAEC,aAAa,EAAE;IAC7C,IAAIiC,EAAE;IACN,MAAM7B,OAAO,GAAG,IAAI9C,gCAAgC,EAAE;IACtD,IAAI,CAAC+F,8BAA8B,CAACjD,OAAO,EAAEL,eAAe,EAAEC,aAAa,CAAC;IAC5E,IAAI,CAACoB,iBAAiB,CAACwB,SAAS,CAACxC,OAAO,CAACkD,QAAQ,EAAE,CAAC;IACpD,CAACrB,EAAE,GAAG,IAAI,CAACV,2BAA2B,MAAM,IAAI,IAAIU,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACsB,aAAa,EAAE;EACnG;EACAC,KAAKA,CAAA,EAAG;IACJ,IAAI,CAAC1B,uBAAuB,EAAE;IAC9B,IAAI,CAACV,iBAAiB,CAACW,WAAW,EAAE;EACxC;EACA0B,iBAAiBA,CAACpD,UAAU,EAAE;IAC1B,IAAI4B,EAAE,EAAEe,EAAE;IACV,MAAM5C,OAAO,GAAG,IAAI9C,gCAAgC,EAAE;IACtD,CAAC2E,EAAE,GAAG,IAAI,CAACX,uBAAuB,MAAM,IAAI,IAAIW,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAAChC,qBAAqB,CAAC,IAAI,CAACkB,UAAU,EAAE,IAAI,CAACE,gBAAgB,EAAEjB,OAAO,EAAEC,UAAU,CAAC;IAC9J,IAAI,CAACe,iBAAiB,CAACwB,SAAS,CAACxC,OAAO,CAACkD,QAAQ,EAAE,CAAC;IACpD,CAACN,EAAE,GAAG,IAAI,CAACzB,2BAA2B,MAAM,IAAI,IAAIyB,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACO,aAAa,EAAE;EACnG;EACAG,gCAAgCA,CAACC,QAAQ,EAAEC,SAAS,EAAE;IAClD,IAAI,CAAC,IAAI,CAACtC,uBAAuB,EAAE;MAC/B,OAAO,CAAC,CAAC;IACb;;IACA,IAAI,CAACmC,iBAAiB,CAACE,QAAQ,CAACtD,UAAU,CAAC;IAC3C,MAAMO,cAAc,GAAG,IAAI,CAACU,uBAAuB,CAAChC,aAAa,CAACqE,QAAQ,CAACtD,UAAU,GAAG,CAAC,CAAC;IAC1F,IAAI,CAACO,cAAc,EAAE;MACjB,OAAO,CAAC,CAAC;IACb;;IACA,MAAMN,UAAU,GAAG,IAAI,CAACa,UAAU,CAACZ,aAAa,EAAE;IAClD,MAAMsD,WAAW,GAAG,IAAI,CAAC1C,UAAU,CAACR,cAAc,CAACgD,QAAQ,CAACtD,UAAU,CAAC;IACvE;IACA,MAAMK,IAAI,GAAImD,WAAW,CAACC,SAAS,CAAC,CAAC,EAAEH,QAAQ,CAACI,MAAM,GAAG,CAAC,CAAC,GACrDH,SAAS,GACTC,WAAW,CAACC,SAAS,CAACH,QAAQ,CAACI,MAAM,GAAG,CAAC,CAAE;IACjD,MAAMlD,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACO,gBAAgB,EAAEf,UAAU,EAAE,IAAI,CAACgB,uBAAuB,CAACxC,mBAAmB,EAAE4B,IAAI,EAAE,IAAI,EAAEE,cAAc,CAAC;IACvI,MAAMoD,UAAU,GAAG,IAAIzG,UAAU,CAACsD,CAAC,CAACG,MAAM,EAAEN,IAAI,EAAE,IAAI,CAACW,gBAAgB,CAAC;IACxE,IAAI2C,UAAU,CAACC,QAAQ,EAAE,KAAK,CAAC,EAAE;MAC7B,OAAO,CAAC,CAAC;IACb;;IACA,MAAMC,UAAU,GAAGF,UAAU,CAACG,sBAAsB,CAACR,QAAQ,CAACI,MAAM,GAAG,CAAC,CAAC;IACzE,OAAOC,UAAU,CAACI,oBAAoB,CAACF,UAAU,CAAC;EACtD;EACAG,oBAAoBA,CAACV,QAAQ,EAAE7F,MAAM,EAAEwG,OAAO,EAAE;IAC5C,MAAMjE,UAAU,GAAGsD,QAAQ,CAACtD,UAAU;IACtC,MAAM0D,MAAM,GAAGJ,QAAQ,CAACI,MAAM;IAC9B,IAAI,CAAC,IAAI,CAACzC,uBAAuB,EAAE;MAC/B,OAAO,IAAI;IACf;IACA,IAAI,CAACmC,iBAAiB,CAACpD,UAAU,CAAC;IAClC,MAAMO,cAAc,GAAG,IAAI,CAACU,uBAAuB,CAAChC,aAAa,CAACe,UAAU,GAAG,CAAC,CAAC;IACjF,IAAI,CAACO,cAAc,EAAE;MACjB,OAAO,IAAI;IACf;IACA,MAAM2D,cAAc,GAAG,IAAI,CAACpD,UAAU,CAACR,cAAc,CAACN,UAAU,CAAC;IACjE,MAAMmE,cAAc,GAAGD,cAAc,CAACT,SAAS,CAAC,CAAC,EAAEC,MAAM,GAAG,CAAC,CAAC,GACxDO,OAAO,GAAGC,cAAc,CAACT,SAAS,CAACC,MAAM,GAAG,CAAC,GAAGjG,MAAM,CAAC;IAC7D,MAAMwC,UAAU,GAAG,IAAI,CAACa,UAAU,CAACsD,uBAAuB,CAACpE,UAAU,EAAE,CAAC,CAAC;IACzE,MAAMqE,MAAM,GAAG5D,YAAY,CAAC,IAAI,CAACO,gBAAgB,EAAEf,UAAU,EAAE,IAAI,CAACgB,uBAAuB,CAACxC,mBAAmB,EAAE0F,cAAc,EAAE,IAAI,EAAE5D,cAAc,CAAC;IACtJ,MAAMoD,UAAU,GAAG,IAAIzG,UAAU,CAACmH,MAAM,CAAC1D,MAAM,EAAEwD,cAAc,EAAE,IAAI,CAACnD,gBAAgB,CAAC;IACvF,OAAO2C,UAAU;EACrB;EACAW,iBAAiBA,CAACtE,UAAU,EAAE;IAC1B,IAAI,CAAC,IAAI,CAACiB,uBAAuB,EAAE;MAC/B,OAAO,IAAI;IACf;IACA,MAAMsD,sBAAsB,GAAG,IAAI,CAACtD,uBAAuB,CAAC1C,qBAAqB,GAAG,CAAC;IACrF,IAAIyB,UAAU,GAAGuE,sBAAsB,EAAE;MACrC,OAAO,KAAK;IAChB;IACA,IAAIvE,UAAU,GAAGuE,sBAAsB,EAAE;MACrC,OAAO,IAAI;IACf;IACA,IAAI,IAAI,CAACzD,UAAU,CAAC0D,aAAa,CAACxE,UAAU,CAAC,GAAG,IAAI,CAAC,iDAAiD;MAClG,OAAO,IAAI;IACf;IACA,OAAO,KAAK;EAChB;EACA;AACJ;AACA;EACIgD,8BAA8BA,CAACjD,OAAO,EAAEL,eAAe,EAAEC,aAAa,EAAE;IACpE,IAAIiC,EAAE;IACN,IAAI,CAAC,IAAI,CAACX,uBAAuB,EAAE;MAC/B;MACA;IACJ;IACA,IAAItB,aAAa,IAAI,IAAI,CAACsB,uBAAuB,CAAC1C,qBAAqB,EAAE;MACrE;MACA;IACJ;IACA,IAAImB,eAAe,IAAI,IAAI,CAACuB,uBAAuB,CAAC1C,qBAAqB,EAAE;MACvE;MACA,IAAI,CAAC0C,uBAAuB,CAACrB,qBAAqB,CAAC,IAAI,CAACkB,UAAU,EAAE,IAAI,CAACE,gBAAgB,EAAEjB,OAAO,EAAEJ,aAAa,CAAC;MAClH;IACJ;IACA,IAAI+C,KAAK,GAAG,IAAI,CAAC+B,eAAe,CAAC/E,eAAe,CAAC;IACjD,MAAMO,UAAU,GAAG,IAAI,CAACa,UAAU,CAACZ,aAAa,EAAE;IAClD,KAAK,IAAIF,UAAU,GAAGN,eAAe,EAAEM,UAAU,IAAIL,aAAa,EAAEK,UAAU,EAAE,EAAE;MAC9E,MAAMK,IAAI,GAAG,IAAI,CAACS,UAAU,CAACR,cAAc,CAACN,UAAU,CAAC;MACvD,MAAMQ,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACO,gBAAgB,EAAEf,UAAU,EAAE,IAAI,CAACgB,uBAAuB,CAACxC,mBAAmB,EAAE4B,IAAI,EAAE,IAAI,EAAEqC,KAAK,CAAC;MAC9H3C,OAAO,CAACW,GAAG,CAACV,UAAU,EAAEQ,CAAC,CAACG,MAAM,CAAC;MACjC+B,KAAK,GAAGlC,CAAC,CAACpB,QAAQ;IACtB;IACA;IACA;IACA,CAACwC,EAAE,GAAG,IAAI,CAACT,mBAAmB,CAACxD,KAAK,MAAM,IAAI,IAAIiE,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAAC8C,aAAa,CAAChF,eAAe,EAAEC,aAAa,GAAG,CAAC,CAAC;EACnI;EACA8E,eAAeA,CAACzE,UAAU,EAAE;IACxB,IAAI2E,mBAAmB,GAAG,IAAI,CAAC7D,UAAU,CAAC8D,+BAA+B,CAAC5E,UAAU,CAAC;IACrF,MAAM6E,mBAAmB,GAAG,EAAE;IAC9B,IAAInG,YAAY,GAAG,IAAI;IACvB,KAAK,IAAIN,CAAC,GAAG4B,UAAU,GAAG,CAAC,EAAE2E,mBAAmB,GAAG,CAAC,IAAIvG,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;MACjE,MAAM0G,qBAAqB,GAAG,IAAI,CAAChE,UAAU,CAAC8D,+BAA+B,CAACxG,CAAC,CAAC;MAChF;MACA,IAAI0G,qBAAqB,KAAK,CAAC,EAAE;QAC7B;MACJ;MACA,IAAIA,qBAAqB,GAAGH,mBAAmB,EAAE;QAC7CE,mBAAmB,CAACE,IAAI,CAAC,IAAI,CAACjE,UAAU,CAACR,cAAc,CAAClC,CAAC,CAAC,CAAC;QAC3DuG,mBAAmB,GAAGG,qBAAqB;QAC3CpG,YAAY,GAAG,IAAI,CAACuC,uBAAuB,CAAChC,aAAa,CAACb,CAAC,GAAG,CAAC,CAAC;QAChE,IAAIM,YAAY,EAAE;UACd;QACJ;MACJ;IACJ;IACA,IAAI,CAACA,YAAY,EAAE;MACfA,YAAY,GAAG,IAAI,CAACuC,uBAAuB,CAACvC,YAAY;IAC5D;IACAmG,mBAAmB,CAACG,OAAO,EAAE;IAC7B,MAAM/E,UAAU,GAAG,IAAI,CAACa,UAAU,CAACZ,aAAa,EAAE;IAClD,IAAIwC,KAAK,GAAGhE,YAAY;IACxB,KAAK,MAAMuG,IAAI,IAAIJ,mBAAmB,EAAE;MACpC,MAAMrE,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACO,gBAAgB,EAAEf,UAAU,EAAE,IAAI,CAACgB,uBAAuB,CAACxC,mBAAmB,EAAEwG,IAAI,EAAE,KAAK,EAAEvC,KAAK,CAAC;MAC/HA,KAAK,GAAGlC,CAAC,CAACpB,QAAQ;IACtB;IACA,OAAOsD,KAAK;EAChB;AACJ;AACA,SAASN,sBAAsBA,CAACvC,SAAS,EAAEqF,gBAAgB,EAAE;EACzD,IAAIrF,SAAS,CAACsF,yBAAyB,EAAE,EAAE;IACvC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC;EACvB;EACA,MAAM1G,mBAAmB,GAAG1B,oBAAoB,CAACQ,GAAG,CAAC2H,gBAAgB,CAAChF,aAAa,EAAE,CAAC;EACtF,IAAI,CAACzB,mBAAmB,EAAE;IACtB,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC;EACvB;EACA,IAAIC,YAAY;EAChB,IAAI;IACAA,YAAY,GAAGD,mBAAmB,CAAC2G,eAAe,EAAE;EACxD,CAAC,CACD,OAAO9D,CAAC,EAAE;IACN7E,iBAAiB,CAAC6E,CAAC,CAAC;IACpB,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC;EACvB;EACA,OAAO,CAAC7C,mBAAmB,EAAEC,YAAY,CAAC;AAC9C;AACA,SAAS+B,YAAYA,CAACX,eAAe,EAAEG,UAAU,EAAExB,mBAAmB,EAAE4B,IAAI,EAAEgF,MAAM,EAAE3C,KAAK,EAAE;EACzF,IAAIlC,CAAC,GAAG,IAAI;EACZ,IAAI/B,mBAAmB,EAAE;IACrB,IAAI;MACA+B,CAAC,GAAG/B,mBAAmB,CAAC6G,eAAe,CAACjF,IAAI,EAAEgF,MAAM,EAAE3C,KAAK,CAAC6C,KAAK,EAAE,CAAC;IACxE,CAAC,CACD,OAAOjE,CAAC,EAAE;MACN7E,iBAAiB,CAAC6E,CAAC,CAAC;IACxB;EACJ;EACA,IAAI,CAACd,CAAC,EAAE;IACJA,CAAC,GAAGxD,mBAAmB,CAAC8C,eAAe,CAAC0F,gBAAgB,CAACvF,UAAU,CAAC,EAAEyC,KAAK,CAAC;EAChF;EACAxF,UAAU,CAACuI,kBAAkB,CAACjF,CAAC,CAACG,MAAM,EAAEN,IAAI,CAAC5C,MAAM,CAAC;EACpD,OAAO+C,CAAC;AACZ;AACA,MAAMsC,0BAA0B,CAAC;EAC7B1F,WAAWA,CAAC0D,UAAU,EAAE4E,WAAW,EAAEC,qBAAqB,EAAE3E,gBAAgB,EAAE;IAC1E,IAAI,CAACF,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAAC4E,WAAW,GAAGA,WAAW;IAC9B,IAAI,CAACC,qBAAqB,GAAGA,qBAAqB;IAClD,IAAI,CAAC3E,gBAAgB,GAAGA,gBAAgB;IACxC,IAAI,CAAC4E,WAAW,GAAG,KAAK;IACxB,IAAI,CAACC,YAAY,GAAG,KAAK;EAC7B;EACAC,OAAOA,CAAA,EAAG;IACN,IAAI,CAACF,WAAW,GAAG,IAAI;EAC3B;EACA3D,aAAaA,CAAA,EAAG;IACZ,IAAI,CAAC8D,4BAA4B,EAAE;EACvC;EACAA,4BAA4BA,CAAA,EAAG;IAC3B,IAAI,IAAI,CAACF,YAAY,IAAI,CAAC,IAAI,CAAC/E,UAAU,CAACkF,kBAAkB,EAAE,IAAI,CAAC,IAAI,CAACC,mBAAmB,EAAE,EAAE;MAC3F;IACJ;IACA,IAAI,CAACJ,YAAY,GAAG,IAAI;IACxBtJ,WAAW,CAAE2J,QAAQ,IAAK;MACtB,IAAI,CAACL,YAAY,GAAG,KAAK;MACzB,IAAI,CAACM,+BAA+B,CAACD,QAAQ,CAAC;IAClD,CAAC,CAAC;EACN;EACA;AACJ;AACA;EACIC,+BAA+BA,CAACD,QAAQ,EAAE;IACtC;IACA;IACA,MAAME,OAAO,GAAGC,IAAI,CAACC,GAAG,EAAE,GAAGJ,QAAQ,CAACK,aAAa,EAAE;IACrD,MAAMC,OAAO,GAAGA,CAAA,KAAM;MAClB,IAAI,IAAI,CAACZ,WAAW,IAAI,CAAC,IAAI,CAAC9E,UAAU,CAACkF,kBAAkB,EAAE,IAAI,CAAC,IAAI,CAACC,mBAAmB,EAAE,EAAE;QAC1F;QACA;MACJ;MACA,IAAI,CAACQ,gCAAgC,EAAE;MACvC,IAAIJ,IAAI,CAACC,GAAG,EAAE,GAAGF,OAAO,EAAE;QACtB;QACA;QACAxJ,WAAW,CAAC4J,OAAO,CAAC;MACxB,CAAC,MACI;QACD;QACA,IAAI,CAACT,4BAA4B,EAAE;MACvC;IACJ,CAAC;IACDS,OAAO,EAAE;EACb;EACA;AACJ;AACA;EACIC,gCAAgCA,CAAA,EAAG;IAC/B,MAAMC,SAAS,GAAG,IAAI,CAAC5F,UAAU,CAACX,YAAY,EAAE;IAChD,MAAMJ,OAAO,GAAG,IAAI9C,gCAAgC,EAAE;IACtD,MAAM0J,EAAE,GAAG9J,SAAS,CAAC+J,MAAM,CAAC,KAAK,CAAC;IAClC,GAAG;MACC,IAAID,EAAE,CAACE,OAAO,EAAE,GAAG,CAAC,EAAE;QAClB;QACA;QACA;QACA;MACJ;MACA,MAAMC,mBAAmB,GAAG,IAAI,CAACC,uBAAuB,CAAChH,OAAO,CAAC;MACjE,IAAI+G,mBAAmB,IAAIJ,SAAS,EAAE;QAClC;MACJ;IACJ,CAAC,QAAQ,IAAI,CAACT,mBAAmB,EAAE;IACnC,IAAI,CAACN,qBAAqB,CAACpD,SAAS,CAACxC,OAAO,CAACkD,QAAQ,EAAE,CAAC;IACxD,IAAI,CAACC,aAAa,EAAE;EACxB;EACA+C,mBAAmBA,CAAA,EAAG;IAClB,IAAI,CAAC,IAAI,CAACP,WAAW,EAAE;MACnB,OAAO,KAAK;IAChB;IACA,OAAO,IAAI,CAACA,WAAW,CAACnH,qBAAqB,GAAG,IAAI,CAACuC,UAAU,CAACX,YAAY,EAAE;EAClF;EACA4G,uBAAuBA,CAAChH,OAAO,EAAE;IAC7B,IAAI,CAAC,IAAI,CAAC2F,WAAW,IAAI,CAAC,IAAI,CAACO,mBAAmB,EAAE,EAAE;MAClD,OAAO,IAAI,CAACnF,UAAU,CAACX,YAAY,EAAE,GAAG,CAAC;IAC7C;IACA,MAAMH,UAAU,GAAG,IAAI,CAAC0F,WAAW,CAACnH,qBAAqB,GAAG,CAAC;IAC7D,IAAI,CAACmH,WAAW,CAAC9F,qBAAqB,CAAC,IAAI,CAACkB,UAAU,EAAE,IAAI,CAACE,gBAAgB,EAAEjB,OAAO,EAAEC,UAAU,CAAC;IACnG,OAAOA,UAAU;EACrB;EACAkD,aAAaA,CAAA,EAAG;IACZ,IAAI,IAAI,CAAC0C,WAAW,EAAE;MAClB;IACJ;IACA,IAAI,IAAI,CAACF,WAAW,CAAC9E,sBAAsB,CAAC,IAAI,CAACE,UAAU,CAAC,EAAE;MAC1D,IAAI,CAAC6E,qBAAqB,CAACnD,8BAA8B,EAAE;IAC/D;EACJ;EACAkC,aAAaA,CAAChF,eAAe,EAAEsH,sBAAsB,EAAE;IACnD,KAAK,IAAIhH,UAAU,GAAGN,eAAe,EAAEM,UAAU,GAAGgH,sBAAsB,EAAEhH,UAAU,EAAE,EAAE;MACtF,IAAI,CAAC0F,WAAW,CAAC7G,mBAAmB,CAACmB,UAAU,GAAG,CAAC,CAAC;IACxD;EACJ;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}